{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine learning project - Urban air pollution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries for data visualization and data analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict, GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "RSEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "air_pollution = pd.read_csv(\"data/Train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data\n",
    "air_pollution.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data for nan's\n",
    "nan_count = air_pollution.isna().sum()\n",
    "nan_percent = air_pollution.isna().sum()/len(air_pollution)*100\n",
    "\n",
    "pd.options.display.max_rows = 4000\n",
    "#print(nan_count)\n",
    "#print(nan_percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two dataframes from data:\n",
    "# 1) Complete dataframe (contains all numerical features)\n",
    "# 2) Incomplete dataframe (contains not all numerical features)\n",
    "feature_set1 = [\n",
    "'Place_ID X Date', \n",
    "'Date', \n",
    "'Place_ID',\n",
    "'target', \n",
    "'target_min', \n",
    "'target_max', \n",
    "'target_variance', \n",
    "'target_count',\n",
    "'L3_NO2_sensor_azimuth_angle',\n",
    "'L3_NO2_solar_azimuth_angle']\n",
    "\n",
    "feature_set2 = [\n",
    "'Place_ID X Date', \n",
    "'Date', \n",
    "'Place_ID', \n",
    "'target', \n",
    "'target_min', \n",
    "'target_max', \n",
    "'target_variance', \n",
    "'target_count', \n",
    "'L3_NO2_sensor_altitude', \n",
    "'L3_NO2_sensor_azimuth_angle', \n",
    "'L3_NO2_sensor_zenith_angle', \n",
    "'L3_NO2_solar_azimuth_angle', \n",
    "'L3_NO2_solar_zenith_angle', \n",
    "'L3_O3_sensor_azimuth_angle', \n",
    "'L3_O3_sensor_zenith_angle', \n",
    "'L3_O3_solar_azimuth_angle', \n",
    "'L3_O3_solar_zenith_angle', \n",
    "'L3_CO_sensor_altitude',\n",
    "'L3_CO_sensor_azimuth_angle',\n",
    "'L3_CO_sensor_zenith_angle',\n",
    "'L3_CO_solar_azimuth_angle',\n",
    "'L3_CO_solar_zenith_angle',\n",
    "'L3_HCHO_solar_azimuth_angle',\n",
    "'L3_HCHO_solar_zenith_angle',\n",
    "'L3_HCHO_sensor_azimuth_angle',\n",
    "'L3_HCHO_sensor_zenith_angle',\n",
    "'L3_AER_AI_sensor_altitude',\n",
    "'L3_AER_AI_sensor_azimuth_angle',\n",
    "'L3_AER_AI_sensor_zenith_angle',\n",
    "'L3_AER_AI_solar_azimuth_angle',\n",
    "'L3_AER_AI_solar_zenith_angle',\n",
    "'L3_CLOUD_sensor_azimuth_angle',\n",
    "'L3_CLOUD_sensor_zenith_angle',\n",
    "'L3_CLOUD_solar_azimuth_angle',\n",
    "'L3_CLOUD_solar_zenith_angle',\n",
    "'L3_SO2_sensor_azimuth_angle',\n",
    "'L3_SO2_sensor_zenith_angle',\n",
    "'L3_SO2_solar_azimuth_angle',\n",
    "'L3_SO2_solar_zenith_angle',\n",
    "'L3_CH4_CH4_column_volume_mixing_ratio_dry_air',\n",
    "'L3_CH4_aerosol_height',\n",
    "'L3_CH4_aerosol_optical_depth',\n",
    "'L3_CH4_sensor_azimuth_angle',\n",
    "'L3_CH4_sensor_zenith_angle',\n",
    "'L3_CH4_solar_azimuth_angle',\n",
    "'L3_CH4_solar_zenith_angle']\n",
    "\n",
    "complete_df = air_pollution.drop(feature_set1, axis=1)\n",
    "incomplete_df = air_pollution.drop(feature_set2, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incomplete_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Decide which features should be analyzed\n",
    "feature_set = \"complete\"\n",
    "#feature_set = \"incomplete\"\n",
    "\n",
    "if feature_set == \"complete\":\n",
    "    df = complete_df\n",
    "if feature_set == \"incomplete\":\n",
    "    df = incomplete_df\n",
    "\n",
    "#df.info()\n",
    "print(\"Feature shape:\", df.shape)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outlier removal (target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outlier removal from target\n",
    "threshold = 300\n",
    "above_threshold = air_pollution[\"target\"] > threshold\n",
    "\n",
    "air_pollution.target[above_threshold] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute (target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_tmp = air_pollution[[\"target\"]].copy()\n",
    "\n",
    "imp_median = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "target_imputed = pd.DataFrame(imp_median.fit_transform(target_tmp))\n",
    "target_imputed.columns = target_tmp.columns\n",
    "target_imputed.index = target_tmp.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multicollinearity (feature reduction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove highly correlated features from feature space to avoid multicollinearity\n",
    "# Highly correlated features defined as: Correlation coefficient > 0.7\n",
    "\n",
    "# Create correlation matrix\n",
    "correlation_matrix = df.corr().abs()\n",
    "\n",
    "# Select upper triangle of correlation matrix\n",
    "upper = correlation_matrix.where(np.triu(np.ones(correlation_matrix.shape), k=1).astype(bool))\n",
    "\n",
    "# Find features with correlation greater than 0.7\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > 0.6)]\n",
    "\n",
    "# Remove features with correlation greater than 0.7\n",
    "df = df.drop(to_drop, axis=1)\n",
    "\n",
    "#df.info()\n",
    "print(\"Feature shape:\", df.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data in train and test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target and split data into train and test set\n",
    "X = df\n",
    "#y = air_pollution[\"target\"]\n",
    "y = target_imputed\n",
    "\n",
    "# Train and test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=RSEED)\n",
    "\n",
    "# Bug report: train_test_split(stratify=y) does not work! Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Our feature vector has {X.shape[0]} observations and {X.shape[1]} features\")\n",
    "print(f\"Our target vector has {y.shape[0]} observations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization (target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize target using MinMaxScaler()\n",
    "get_target_train = y_train.values.reshape(-1,1)\n",
    "get_target_test = y_test.values.reshape(-1,1)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "y_train_fit = scaler.fit(get_target_train)\n",
    "y_train = pd.DataFrame(y_train_fit.transform(get_target_train))\n",
    "y_test = pd.DataFrame(y_train_fit.transform(get_target_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pipeline to impute and scale feature values\n",
    "num_pipeline = Pipeline([\n",
    "    ('median_imputer', SimpleImputer(strategy='median')),\n",
    "    ('minmax_scaler', MinMaxScaler())\n",
    "])\n",
    "\n",
    "num_features = X_train.columns\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', num_pipeline, num_features)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model initiation: KNN regressor\n",
    "pipe_knn = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('knn', KNeighborsRegressor())\n",
    "])\n",
    "\n",
    "# Model initiation: Decision tree\n",
    "pipe_tree = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('tree', DecisionTreeRegressor())\n",
    "])\n",
    "\n",
    "# Model initiation: Random forest\n",
    "pipe_forest = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('forest', RandomForestRegressor())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check: Model performance on train set (without hyperparameter tuning) \n",
    "y_train_pred = cross_val_predict(pipe_linreg, X_train, y_train, cv=5)\n",
    "#y_train_pred = cross_val_predict(pipe_knn, X_train, y_train, cv=5)\n",
    "#y_train_pred = cross_val_predict(pipe_tree, X_train, y_train, cv=5)\n",
    "#y_train_pred = cross_val_predict(pipe_forest, X_train, y_train, cv=5)\n",
    "\n",
    "rmse = mean_squared_error(y_train, y_train_pred, squared=False)\n",
    "print(\"Training\")\n",
    "print(\"RSME: \", rmse)\n",
    "print(\"_\"*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning \n",
    "\n",
    "# Define hyperparameter search space for GridSearch\n",
    "param_knn = {'knn__n_neighbors': [5, 7, 9, 11, 13],\n",
    "             'knn__weights': ['uniform', 'distance'],\n",
    "             'knn__algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']  \n",
    "            }\n",
    "\n",
    "param_tree = {'tree__max_depth': [10, 50, 100],\n",
    "              'tree__min_samples_leaf': np.arange(5,55,10),\n",
    "              'tree__criterion': ['squared_error', 'absolute_error', 'friedman_mse', 'poisson'],\n",
    "              }\n",
    "\n",
    "param_forest = {'forest__n_estimators': np.arange(50,200,50),\n",
    "                'forest__max_depth': [5, 10, 15, 50],\n",
    "                'forest__min_samples_leaf': [50, 100, 150],\n",
    "                'forest__max_features': ['sqrt']\n",
    "                }\n",
    "\n",
    "# Use GridSearch\n",
    "grid_knn = GridSearchCV(pipe_knn, param_grid=param_knn, cv=5, scoring='neg_root_mean_squared_error', \n",
    "                           verbose=5, n_jobs=-1)\n",
    "\n",
    "grid_tree = GridSearchCV(pipe_tree, param_grid=param_tree, cv=5, scoring='neg_root_mean_squared_error', \n",
    "                           verbose=5, n_jobs=-1)\n",
    "\n",
    "grid_forest = GridSearchCV(pipe_forest, param_grid=param_forest, cv=5, scoring='neg_root_mean_squared_error', \n",
    "                           verbose=5, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model: Linear regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Bug report: Linear regressor\n",
    "grid_linreg.fit(X_train,y_train)\n",
    "y_test_pred = grid_linreg.predict(X_test)\n",
    "\n",
    "rmse = mean_squared_error(y_test, y_test_pred, squared=False)\n",
    "print(\"Testing\")\n",
    "print(\"RSME: \", rmse)\n",
    "print(\"_\"*10)\n",
    "\n",
    "#grid_linreg.fit(X_train,y_train)\n",
    "#best_estimator_linreg = grid_linreg.best_estimator_\n",
    "#print(\"Best parameters: \", grid_linreg.best_params_)\n",
    "#print(\"RMSE: \", abs(grid_linreg.best_score_)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model: KNN regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN regressor\n",
    "#grid_knn.fit(X_train,y_train)\n",
    "grid_knn.fit(X_train,y_train.values.ravel())\n",
    "best_estimator_knn = grid_knn.best_estimator_\n",
    "print(\"Best parameters: \", grid_knn.best_params_)\n",
    "print(\"KNN - RMSE: \", abs(grid_knn.best_score_)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model: Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision tree regressor\n",
    "#grid_tree.fit(X_train,y_train)\n",
    "grid_tree.fit(X_train,y_train.values.ravel())\n",
    "best_estimator_tree = grid_tree.best_estimator_\n",
    "print(\"Best parameters: \", grid_tree.best_params_)\n",
    "print(\"Tree - RMSE: \", abs(grid_tree.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model: Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forest regressor\n",
    "#grid_forest.fit(X_train,y_train)\n",
    "grid_forest.fit(X_train,y_train.values.ravel())\n",
    "best_estimator_forest = grid_forest.best_estimator_\n",
    "print(\"Best parameters: \", grid_forest.best_params_)\n",
    "print(\"Forest - RMSE: \", abs(grid_forest.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN regressor\n",
    "knn_pred = best_estimator_knn.predict(X_test)\n",
    "print(\"KNN - RMSE: {:.3f}\".format(mean_squared_error(y_test, knn_pred, squared=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision tree regressor\n",
    "tree_pred = best_estimator_tree.predict(X_test)\n",
    "print(\"Tree - RMSE: {:.3f}\".format(mean_squared_error(y_test, tree_pred, squared=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forest regressor\n",
    "forest_pred = best_estimator_forest.predict(X_test)\n",
    "print(\"Forest - RMSE: {:.3f}\".format(mean_squared_error(y_test, forest_pred, squared=False)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble Methods: XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Regressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Model initiation: XGBOOST_tree\n",
    "pipe_xgboost_tree = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('xgboost_tree', XGBRegressor())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameter search space for GridSearch\n",
    "param_xgboost_tree = {'xgboost_tree__eta': [0.1, 0.15, 0.2, 0.25, 0.3, 0.4],\n",
    "                      'xgboost_tree__max_depth': [2, 3, 4, 5, 6],\n",
    "                      'xgboost_tree__lambda': [1.0],\n",
    "                      'xgboost_tree__alpha': [0.2,0.4, 0.6, 0.8, 1.0],  \n",
    "                      }\n",
    "\n",
    "# Use GridSearch\n",
    "grid_xgboost_tree = GridSearchCV(pipe_xgboost_tree, param_grid=param_xgboost_tree, cv=5, scoring='neg_root_mean_squared_error', \n",
    "                           verbose=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGboost regressor tree based\n",
    "grid_xgboost_tree.fit(X_train,y_train.values.ravel())\n",
    "best_estimator_xgboost_tree = grid_xgboost_tree.best_estimator_\n",
    "print(\"Best parameters: \", grid_xgboost_tree.best_params_)\n",
    "print(\"XGBoost_tree - RMSE: \", abs(grid_xgboost_tree.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision XGboost_tree regressor\n",
    "xgboost_tree_pred = best_estimator_xgboost_tree.predict(X_test)\n",
    "print(\"XGboost_tree - RMSE: {:.3f}\".format(mean_squared_error(y_test, xgboost_tree_pred, squared=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision XGboost_tree regressor\n",
    "xgboost_tree_pred = best_estimator_xgboost_tree.predict(X_test)\n",
    "print(\"XGboost_tree - RMSE: {:.3f}\".format(mean_squared_error(y_test, xgboost_tree_pred, squared=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xgb_reg = XGBRegressor()\n",
    "#xgb_reg = XGBRegressor(alpha=0.4, eta=0.25, max_depth=6)\n",
    "xgb_reg = XGBRegressor(alpha=1.0, eta=0.2, max_depth=6)\n",
    "xgb_reg.fit(X_train, y_train)\n",
    "\n",
    "y_pred_best_train = xgb_reg.predict(X_train)\n",
    "y_pred_best = xgb_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_best = mean_squared_error(y_test,y_pred_best)\n",
    "print(\"RMSE\", rmse_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_importances = pd.Series(xgb_reg.feature_importances_, index=X.columns)\n",
    "print(feat_importances.sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_importances.nlargest(5).plot(kind='barh')\n",
    "plt.savefig('feature_importance.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = y_test - y_pred_best.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = sns.scatterplot(x=np.array(y_test).ravel(), y=np.array(residuals).ravel())\n",
    "fig.set_title(\"\")\n",
    "fig.set_xlabel(\"\")\n",
    "fig.set_ylabel(\"Residuals\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = sns.pairplot(data=X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute features, where values is missing with median values\n",
    "X_train_tmp = X_train.copy()\n",
    "X_test_tmp = X_test.copy()\n",
    "\n",
    "imp_median = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "X_train_imputed = pd.DataFrame(imp_median.fit_transform(X_train_tmp))\n",
    "X_train_imputed.columns = X_train_tmp.columns\n",
    "X_train_imputed.index = X_train_tmp.index\n",
    "\n",
    "X_test_imputed = pd.DataFrame(imp_median.fit_transform(X_test_tmp))\n",
    "X_test_imputed.columns = X_test_tmp.columns\n",
    "X_test_imputed.index = X_test_tmp.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize features using MinMaxScaler()\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "columns = X_train_imputed.columns\n",
    "X_train_imputed[columns] = scaler.fit_transform(X_train_imputed[columns])\n",
    "X_test_imputed[columns] = scaler.fit_transform(X_test_imputed[columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose baseline model \n",
    "# TODO Compute linear models with one feature to identify best feature (lowest RMSE)\n",
    "n_features = X_train_imputed.columns\n",
    "\n",
    "all_rmses = []\n",
    "\n",
    "for feature in n_features:\n",
    "    \n",
    "    X_train_baseline = X_train_imputed[[feature]]\n",
    "    X_test_baseline = X_test_imputed[[feature]]\n",
    "\n",
    "    # Linear regression model\n",
    "    linear_mdl = LinearRegression()\n",
    "    linear_mdl.fit(X_train_baseline,y_train)\n",
    "\n",
    "    y_pred_train = linear_mdl.predict(X_train_baseline)\n",
    "    y_pred = linear_mdl.predict(X_test_baseline)\n",
    "\n",
    "    rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "\n",
    "    #all_features.append(feature)\n",
    "    all_rmses.append([feature, rmse])\n",
    "\n",
    "all_rmses = pd.DataFrame(all_rmses).sort_values(by=1, ascending=True)\n",
    "print(all_rmses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute baseline model\n",
    "#baseline_feature = \"L3_HCHO_tropospheric_HCHO_column_number_density\"\n",
    "baseline_feature = \"u_component_of_wind_10m_above_ground\"\n",
    "\n",
    "X_train_baseline = X_train_imputed[[baseline_feature]]\n",
    "X_test_baseline = X_test_imputed[[baseline_feature]]\n",
    "\n",
    "# Linear regression model\n",
    "linear_mdl = LinearRegression()\n",
    "linear_mdl.fit(X_train_baseline,y_train)\n",
    "\n",
    "y_pred_train = linear_mdl.predict(X_train_baseline)\n",
    "y_pred = linear_mdl.predict(X_test_baseline)\n",
    "\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "print(\"Linear regression - Baseline model\")\n",
    "print(\"RSME: \", rmse)\n",
    "print(\"_\"*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot baseline model\n",
    "sns.set_style(\"ticks\")\n",
    "plt.rcParams[\"figure.figsize\"] = (7,4)\n",
    "\n",
    "plt.scatter(X_train_baseline, y_train, color='grey', alpha=0.25)\n",
    "plt.plot(X_train_baseline, y_pred_train, '-', color='black', linewidth=2)\n",
    "plt.title(\"Air pollution (baseline model)\")\n",
    "plt.ylabel('PM2.5 (µg/m^3)')\n",
    "#plt.xlabel('L3 HCHO tropospheric HCHO column number density (mol/m^2)');\n",
    "plt.xlabel(baseline_feature);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = sns.histplot(y_train)\n",
    "fig.set_title(\"Air quality metric (AQM)\")\n",
    "fig.set_xlabel(\"Norm. AQM\")\n",
    "fig.set_ylabel(\"Count\")\n",
    "\n",
    "plt.axvline(0.5)\n",
    "plt.savefig('apm_hist.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = sns.boxplot(y_train)\n",
    "fig.set_title(\"Air quality metric (AQM)\")\n",
    "fig.set_xlabel(\"\")\n",
    "fig.set_ylabel(\"Norm. AQM\")\n",
    "\n",
    "plt.savefig('apm_box.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA of sensor features (Humidity, Wind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eda_df = X_train_imputed.copy()\n",
    "eda_df[\"target\"] = y_train\n",
    "\n",
    "#eda_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = sns.lmplot(data=eda_df, x=\"relative_humidity_2m_above_ground\", y=\"target\", scatter_kws={'alpha':0.1})\n",
    "fig.set_titles(\"AQM vs. Humidity\")\n",
    "fig.set_axis_labels(\"Norm. Humidity\",\"Norm. AQM\")\n",
    "\n",
    "plt.savefig('humidity.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = sns.lmplot(data=eda_df, x=\"u_component_of_wind_10m_above_ground\", y=\"target\", scatter_kws={'alpha':0.1})\n",
    "fig.set_titles(\"AQM vs. Wind\")\n",
    "fig.set_axis_labels(\"Norm. Wind\",\"Norm. AQM\")\n",
    "\n",
    "plt.savefig('wind.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA of satellite features (Gases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
